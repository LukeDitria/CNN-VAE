{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as Datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as vutils\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import Helpers as hf\n",
    "from RES_VAE_Dynamic import VAE\n",
    "from vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "image_size = 64\n",
    "lr = 1e-4\n",
    "nepoch = 100\n",
    "start_epoch = 0\n",
    "dataset_root = \"/media/luke/Quick Storage/Data\"\n",
    "save_dir = os.getcwd()\n",
    "model_name = \"STL10\"\n",
    "load_checkpoint  = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "gpu_indx  = 0\n",
    "device = torch.device(gpu_indx if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_STL10(transform, batch_size, download = True, root = \"/data\"):\n",
    "    print(\"Loading trainset...\")\n",
    "    trainset = Datasets.STL10(root=root, split='unlabeled', transform=transform, download=download)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    \n",
    "    print(\"Loading testset...\")\n",
    "    testset = Datasets.STL10(root=root, split='test', download=download, transform=transform)\n",
    "\n",
    "    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    print(\"Done!\")\n",
    "\n",
    "    return trainloader, testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD way of getting features and calculating loss - Not used\n",
    "\n",
    "# #create an empty layer that will simply record the feature map passed to it.\n",
    "# class GetFeatures(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(GetFeatures, self).__init__()\n",
    "#         self.features = None\n",
    "#     def forward(self, x):\n",
    "#         self.features = x\n",
    "#         return x\n",
    "\n",
    "# #download the pre-trained weights of the VGG-19 and append them to an array of layers .\n",
    "# #we insert a GetFeatures layer after a relu layer.\n",
    "# #layers_deep controls how deep we go into the network\n",
    "# def get_feature_extractor(layers_deep = 7):\n",
    "#     C_net = models.vgg19(pretrained=True).to(device)\n",
    "#     C_net = C_net.eval()\n",
    "    \n",
    "#     layers = []\n",
    "#     for i in range(layers_deep):\n",
    "#         layers.append(C_net.features[i])\n",
    "#         if isinstance(C_net.features[i], nn.ReLU):\n",
    "#             layers.append(GetFeatures())\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "# #this function calculates the L2 loss (MSE) on the feature maps copied by the layers_deep\n",
    "# #between the reconstructed image and the origional\n",
    "# def feature_loss(img, recon_data, feature_extractor):\n",
    "#     img_cat = torch.cat((img, torch.sigmoid(recon_data)), 0)\n",
    "#     out = feature_extractor(img_cat)\n",
    "#     loss = 0\n",
    "#     for i in range(len(feature_extractor)):\n",
    "#         if isinstance(feature_extractor[i], GetFeatures):\n",
    "#             loss += (feature_extractor[i].features[:(img.shape[0])] - feature_extractor[i].features[(img.shape[0]):]).pow(2).mean()\n",
    "#     return loss/(i+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.RandomHorizontalFlip(0.5),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(0.5, 0.5)])\n",
    "\n",
    "trainloader, testloader = get_data_STL10(transform, batch_size, download=False, root=dataset_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a test image batch from the testloader to visualise the reconstruction quality\n",
    "dataiter = iter(testloader)\n",
    "test_images, _ = dataiter.next()\n",
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,10))\n",
    "out = vutils.make_grid(test_images[0:8], normalize=True)\n",
    "plt.imshow(out.numpy().transpose((1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the feature loss module\n",
    "feature_extractor = VGG19().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create VAE network\n",
    "vae_net = VAE(channel_in=3, ch=64, blocks=(1, 2, 4, 8), latent_channels=512).to(device)\n",
    "# setup optimizer\n",
    "optimizer = optim.Adam(vae_net.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "#Loss function\n",
    "loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the save directory if it does note exist\n",
    "if not os.path.isdir(save_dir + \"/Models\"):\n",
    "    os.makedirs(save_dir + \"/Models\")\n",
    "if not os.path.isdir(save_dir + \"/Results\"):\n",
    "    os.makedirs(save_dir + \"/Results\")\n",
    "\n",
    "if load_checkpoint:\n",
    "    checkpoint = torch.load(save_dir + \"/Models/\" + model_name + \"_\" + str(image_size) + \".pt\", map_location = \"cpu\")\n",
    "    print(\"Checkpoint loaded\")\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    vae_net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    start_epoch = checkpoint[\"epoch\"]\n",
    "    loss_log = checkpoint[\"loss_log\"]\n",
    "else:\n",
    "    #If checkpoint does exist raise an error to prevent accidental overwriting\n",
    "    if os.path.isfile(save_dir + \"/Models/\" + model_name + \"_\" + str(image_size) + \".pt\"):\n",
    "        raise ValueError(\"Warning Checkpoint exists\")\n",
    "    else:\n",
    "        print(\"Starting from scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in trange(start_epoch, nepoch, leave=False):\n",
    "    vae_net.train()\n",
    "    for i, (images, _) in enumerate(tqdm(trainloader, leave=False)):\n",
    "        images = images.to(device)\n",
    "\n",
    "        recon_img, mu, logvar = vae_net(images)\n",
    "        #VAE loss\n",
    "        kl_loss = hf.kl_loss(mu, logvar)\n",
    "        mse_loss = F.mse_loss(recon_img, images)\n",
    "        \n",
    "        #Perception loss\n",
    "        feat_in = torch.cat((recon_img, images), 0)\n",
    "        feature_loss = feature_extractor(feat_in)\n",
    "        \n",
    "        loss = kl_loss + mse_loss + feature_loss\n",
    "    \n",
    "        loss_log.append(loss.item())\n",
    "        vae_net.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    #In eval mode the model will use mu as the encoding instead of sampling from the distribution\n",
    "    vae_net.eval()\n",
    "    with torch.no_grad():\n",
    "        recon_img, _, _ = vae_net(test_images.to(device))\n",
    "        img_cat = torch.cat((recon_img.cpu(), test_images), 2)\n",
    "        \n",
    "        vutils.save_image(img_cat,\n",
    "                          \"%s/%s/%s_%d.png\" % (save_dir, \"Results\" , model_name, image_size),\n",
    "                          normalize=True)\n",
    "\n",
    "        #Save a checkpoint\n",
    "        torch.save({\n",
    "                    'epoch'                         : epoch,\n",
    "                    'loss_log'                      : loss_log,\n",
    "                    'model_state_dict'              : vae_net.state_dict(),\n",
    "                    'optimizer_state_dict'          : optimizer.state_dict()\n",
    "\n",
    "                     }, save_dir + \"/Models/\" + model_name + \"_\" + str(image_size) + \".pt\")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
